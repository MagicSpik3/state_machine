import sys
import os
import argparse
import logging
import shutil
from typing import List
from pathlib import Path

# --- CORE COMPONENTS ---
from spec_writer.review import ProjectArchitect
from code_forge.refiner import CodeRefiner
from code_forge.R_runner import RRunner
from code_forge.generator import RGenerator
from spss_engine.pipeline import CompilerPipeline
from spss_engine.repository import Repository
from spss_engine.spss_runner import PsppRunner
from spec_writer.graph import GraphGenerator
from spec_writer.describer import SpecGenerator
from common.llm import OllamaClient

# Setup Logging (Default INFO)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s', datefmt='%H:%M:%S')
logger = logging.getLogger("Statify")

def ensure_output_dir(base_output_dir: str, relative_path: str) -> str:
    """Creates the subdirectory structure in the output folder."""
    rel_dir = os.path.dirname(relative_path)
    target_dir = os.path.join(base_output_dir, rel_dir)
    os.makedirs(target_dir, exist_ok=True)
    return target_dir

def process_file(full_path: str, relative_path: str, output_root: str, model: str, generate_code: bool, refine_mode: bool):
    """
    Orchestrates the conversion pipeline for a single file.
    """
    logger.info(f"üìÇ Processing {relative_path}...")
    
    # 0. Setup Output Location
    target_dir = ensure_output_dir(output_root, relative_path)
    base_name = os.path.splitext(os.path.basename(full_path))[0]
    
    with open(full_path, 'r', encoding='utf-8') as f:
        code = f.read()

    # 1. Engine Phase (Parsing)
    logger.info("  ‚öôÔ∏è  Compiling Logic Graph...")
    pipeline = CompilerPipeline()
    pipeline.process(code)
    
    # 2. Optimization Phase
    dead_vars = pipeline.analyze_dead_code()
    if dead_vars:
        logger.info(f"  üßπ Detected {len(dead_vars)} dead variable versions.")

    # 3. Verification Phase (Ground Truth Probe)
    runtime_values = {}
    if shutil.which("pspp"):
        logger.info("  üî¨ Running Verification Probe (PSPP)...")
        try:
            runner = PsppRunner()
            runtime_values = runner.run_and_probe(full_path, output_dir=target_dir)
            logger.info(f"  ‚úÖ Verification Successful. Captured {len(runtime_values)} values.")
        except Exception as e:
            # In verbose mode, this would show the full stack trace
            logger.warning(f"  ‚ö†Ô∏è Verification Failed: {e}") 
            logger.debug(f"PSPP Error Details:", exc_info=True)
    else:
        logger.info("  ‚ÑπÔ∏è  PSPP not found. Skipping verification.")

    # 4. Visualization Phase
    img_name = os.path.join(target_dir, f"{base_name}_flow")
    logger.info(f"  üé® Rendering Graph to {img_name}.png...")
    
    try:
        graph_gen = GraphGenerator(pipeline.state_machine)
        graph_gen.render(img_name)
    except Exception as e:
        logger.error(f"  ‚ùå Graph Generation Failed: {e}")

    # 5. Specification Phase
    logger.info(f"  ü§ñ Connecting to AI ({model})...")
    client = OllamaClient(model=model)
    generator = SpecGenerator(pipeline.state_machine, client)
    
    logger.info("  üìù Writing Specification...")
    spec_content = generator.generate_report(dead_ids=dead_vars, runtime_values=runtime_values)
    
    report_file = os.path.join(target_dir, f"{base_name}_spec.md")
    with open(report_file, "w") as f:
        f.write(spec_content)

    # 6. Code Generation & Verification Phase
    if generate_code:
        logger.info("  ‚öôÔ∏è  Generating R Code...")
        r_gen = RGenerator(pipeline.state_machine)
        
        # A. Rough Draft
        r_code = r_gen.generate_script()
        
        # B. AI Refinement
        if refine_mode:
            logger.info(f"  üß† Refining code with qwen2.5-coder:latest...")
            try:
                refiner = CodeRefiner(model="qwen2.5-coder:latest")
                refined = refiner.refine(r_code)
                if refined:
                    r_code = refined
            except Exception as e:
                logger.warning(f"  ‚ö†Ô∏è Refinement failed, reverting to basic translation: {e}")

        # C. Save the Code
        r_path = os.path.join(target_dir, f"{base_name}.R")
        with open(r_path, "w", encoding="utf-8") as f:
            f.write(r_code)
            
        # D. Description File
        pkg_name = "".join(x for x in base_name if x.isalnum())
        desc_content = r_gen.generate_description(pkg_name)
        desc_path = os.path.join(target_dir, "DESCRIPTION")
        with open(desc_path, "w", encoding="utf-8") as f:
            f.write(desc_content)
        logger.info(f"  üì¶ Saved Package Metadata: {desc_path}")
        
        # 7. Equivalence Check (Run ONLY if we have ground truth)
        if runtime_values:
            logger.info("  ‚öñÔ∏è  Running Equivalence Check (Black Box vs White Box)...")
            
            # üü¢ FIX: Pass the StateMachine to RRunner so it can discover inputs!
            r_runner = RRunner(r_path, state_machine=pipeline.state_machine)
            
            # üü¢ FIX: Call without arguments to trigger auto-discovery
            r_results = r_runner.run_and_capture()
            
            matches = 0
            mismatches = 0
            
            for key, legacy_raw in runtime_values.items():
                key = key.upper()
                if key in r_results:
                    new_val = r_results[key]
                    try:
                        leg_float = float(legacy_raw)
                        new_float = float(new_val)
                        if abs(leg_float - new_float) < 0.001:
                            matches += 1
                        else:
                            mismatches += 1
                            logger.error(f"    ‚ùå MISMATCH on {key}: SPSS={leg_float} | R={new_float}")
                    except (ValueError, TypeError):
                        leg_str = str(legacy_raw).strip().upper()
                        new_str = str(new_val).strip().upper()
                        if leg_str == new_str:
                            matches += 1
                        else:
                            mismatches += 1
                            logger.error(f"    ‚ùå MISMATCH on {key}: SPSS='{leg_str}' | R='{new_str}'")

            if matches > 0 and mismatches == 0:
                logger.info(f"  ‚úÖ PROVEN EQUIVALENCE! ({matches} variables match perfectly)")
            elif mismatches > 0:
                logger.warning(f"  ‚ö†Ô∏è  Equivalence Check Failed: {mismatches} mismatches found.")
            else:
                logger.warning("  ‚ùì No overlapping variables found to compare.")

        # 8. Architectural Review
        if refine_mode: 
            logger.info("  üèõÔ∏è  Summoning the Architect...")
            
            architect = ProjectArchitect(OllamaClient(model="mistral:instruct"))
            logger.info("  üßê The Architect is reviewing the project...")
            review_report = architect.review(r_code, spec_content)
            
            review_path = os.path.join(target_dir, f"{base_name}_REVIEW.md")
            with open(review_path, 'w') as f:
                f.write(review_report)
                
            logger.info(f"  üìù Architectural Review Saved: {review_path}")

def process_directory(source_root: str, output_root: str, model: str, generate_code: bool, refine_mode: bool):
    logger.info(f"üìÇ Scanning Repository: {source_root}")
    logger.info(f"üíæ Output Target: {output_root}")
    
    repo = Repository(source_root)
    repo.scan()
    
    files = repo.list_files()
    total = len(files)
    logger.info(f"üîé Found {total} valid SPSS files.")
    
    errors = []
    
    for i, rel_path in enumerate(files, 1):
        full_path = repo.get_full_path(rel_path)
        print("-" * 60)
        logger.info(f"[{i}/{total}] Starting: {rel_path}")
        
        try:
            process_file(full_path, rel_path, output_root, model, generate_code, refine_mode)
        except Exception as e:
            logger.error(f"‚ùå Failed to process {rel_path}: {e}", exc_info=True) # Full stack trace
            errors.append(rel_path)

    print("=" * 60)
    logger.info(f"üèÅ Batch Complete. Success: {total - len(errors)}/{total}")
    if errors:
        logger.info(f"‚ö†Ô∏è Failed files: {errors}")

def main():
    parser = argparse.ArgumentParser(description="Statify: Convert Legacy Code to Human Specs")
    parser.add_argument("path", help="Path to SPSS source file or directory")
    parser.add_argument("--output", "-o", default="./dist", help="Directory to save generated documentation")
    parser.add_argument("--model", default="mistral:instruct", help="Ollama model to use")
    parser.add_argument("--code", action="store_true", help="Generate R code alongside the spec")
    parser.add_argument("--refine", action="store_true", help="Use AI to refine the generated code")
    
    # üü¢ NEW: Verbose Flag
    parser.add_argument("--verbose", "-v", action="store_true", help="Enable verbose debug logging")
    
    args = parser.parse_args()
    
    # üü¢ NEW: Configure Logging Level
    if args.verbose:
        logger.setLevel(logging.DEBUG)
        logging.getLogger().setLevel(logging.DEBUG)
        logger.debug("üîß Verbose mode enabled")
    
    source_path = os.path.abspath(args.path)
    output_path = os.path.abspath(args.output)
    
    if os.path.isfile(source_path):
        root_dir = os.path.dirname(source_path)
        rel_path = os.path.relpath(source_path, root_dir)
        process_file(source_path, rel_path, output_path, args.model, args.code, args.refine)
    elif os.path.isdir(source_path):
        process_directory(source_path, output_path, args.model, args.code, args.refine)
    else:
        logger.error(f"Path not found: {source_path}")

if __name__ == "__main__":
    main()